{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Indexed Queries in PyTables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    ">\n",
    "> * Learn how to index columns in tables for accelerating queries\n",
    "> * Experiment with different indexes and/or compression\n",
    "> * Discover some limitations of indexed queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing is a general technique for adding data structures that can accelerate queries.  Let's see how PyTables makes use of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalized case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continue from the previous notebook\n",
    "data_dir = 'queries'\n",
    "h5denorm = \"compression/blosc-zstd-5-shuffle-denorm.h5\"\n",
    "h5norm = \"compression/blosc-zstd-5-shuffle.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queries\\\\movielens-denorm-indexed.h5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx = os.path.join(data_dir, \"movielens-denorm-indexed.h5\")\n",
    "if os.path.exists(h5idx):\n",
    "    os.unlink(h5idx)\n",
    "shutil.copyfile(h5denorm, h5idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx, mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.56 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the 'title' column\n",
    "h5lens = h5i.root.lens\n",
    "blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "%time h5lens.cols.title.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this time is 100x less than without using indexing.  What if we index the `rating` column too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 845 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the rating column\n",
    "%time h5lens.cols.rating.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so although small, this represents another improvement in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queries\\\\movielens-norm-indexed.h5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx = os.path.join(data_dir, \"movielens-norm-indexed.h5\")\n",
    "if os.path.exists(h5idx):\n",
    "    os.unlink(h5idx)\n",
    "shutil.copyfile(h5norm, h5idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx, mode=\"a\")\n",
    "h5ratings = h5i.root.ratings\n",
    "h5movies = h5i.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 626 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the rating column\n",
    "blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "%time h5ratings.cols.rating.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 489 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, in this case indexing the rating column has not served to accelerate the query (at first sight at least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 688 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the movie_id column\n",
    "%time h5ratings.cols.movie_id.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we see a better acceleration in the query, but cannot compete with the query speed for the denormalized case (which is ~10x faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 99M\n",
      "-rw-r--r-- 1 tomkooij 197613  79M Jun 22 12:58 keyvalue.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 9.9M Jun 23 10:39 movielens-denorm-indexed.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 9.6M Jun 23 10:40 movielens-norm-indexed.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not created an index for the title for the normalized case.  Create such an index and determine if there is a noticeable speed-up or not.  Explain why you think that is the case.  Note: the times for a cold query can be **significatively** different from a hot query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movielens-norm-indexed2.h5'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx2 = \"movielens-norm-indexed2.h5\"\n",
    "if os.path.exists(h5idx2):\n",
    "    os.unlink(h5idx2)\n",
    "shutil.copyfile(h5idx, h5idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx2, mode=\"a\")\n",
    "h5ratings = h5i.root.ratings\n",
    "h5movies = h5i.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Solution starts here\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the movie_id column\n",
    "%time h5movies.cols.title.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 284 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So the first time that the query is done after the cache is built (cold query), the time has been reduced a bit but not too much.  For subsequent queries (hot queries), the times are better, but not reaching the denormalized table either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Query size vs speed (indexed queries vs non-indexed queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a (large) file containing some `(key, value)` pairs. The `value` is an `int64`. The `key` is a random 10-byte string, to simulate actual data, with normal compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 20  # append 20 blocks of 1M rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block:  1\n",
      "block:  2\n",
      "block:  3\n",
      "block:  4\n",
      "block:  5\n",
      "block:  6\n",
      "block:  7\n",
      "block:  8\n",
      "block:  9\n",
      "block:  10\n",
      "block:  11\n",
      "block:  12\n",
      "block:  13\n",
      "block:  14\n",
      "block:  15\n",
      "block:  16\n",
      "block:  17\n",
      "block:  18\n",
      "block:  19\n",
      "block:  20\n"
     ]
    }
   ],
   "source": [
    "# adapted from: https://stackoverflow.com/questions/20769818/\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "class KeyValue(tables.IsDescription):\n",
    "    key = tables.StringCol(itemsize=10, dflt=\" \", pos=0)  \n",
    "    value = tables.Int64Col(dflt=0, pos=1)\n",
    "\n",
    "fn = os.path.join(data_dir, \"keyvalue.h5\")\n",
    "\n",
    "with tables.open_file(fn, \"w\") as f:    \n",
    "    filters = tables.Filters(complevel=5, complib='blosc')\n",
    "    kv = f.create_table(\"/\", \"keyvalues\", KeyValue, filters=filters)\n",
    "\n",
    "    for j in range(1, N+1):\n",
    "        values = []\n",
    "        print('block: ', j)\n",
    "        for _ in range(100000):\n",
    "            key = \"\".join(random.sample(string.ascii_uppercase, 10))  # slow!\n",
    "            value = random.randint(0, 1000000)\n",
    "            values.append((key, value))\n",
    "        kv.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/keyvalues (Table(2000000,), shuffle, blosc(5)) ''\n",
      "  description := {\n",
      "  \"key\": StringCol(itemsize=10, shape=(), dflt=b' ', pos=0),\n",
      "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (3640,)\n",
      "  Data dump:\n",
      "[0] (b'OPLGDUVKMQ', 276136)\n",
      "[1] (b'SPTKNVBHWI', 522686)\n",
      "[2] (b'LJZBYWGOTE', 450625)\n",
      "[3] (b'FLEYROGDWB', 262028)\n",
      "[4] (b'GJUVFCPQKH', 145975)\n",
      "[5] (b'QKLSWEYHFB', 87708)\n",
      "[6] (b'STFJEAPZQD', 590688)\n",
      "[7] (b'BSVHUZRNAL', 469617)\n",
      "[8] (b'YFSVBOCLTX', 847850)\n",
      "[9] (b'EZRVMYCIFP', 571338)\n"
     ]
    }
   ],
   "source": [
    "!ptdump -v -R10 {fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Query the `value` column and compare different query (result) sizes:\n",
    "Compare indexed queries with unindexed queries.\n",
    "*Optional: compare different compression levels and codecs* \n",
    "\n",
    "\n",
    "For example: `'(value > 100000) & (value <1000010)'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Results start here\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value=10 : len=24\n",
      "max_value=50 : len=95\n",
      "max_value=100 : len=206\n",
      "max_value=1000 : len=2061\n",
      "max_value=10000 : len=20102\n",
      "\n",
      "without index:\n",
      "56.3 ms ± 3.86 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "55.3 ms ± 901 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "58 ms ± 2.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "56.6 ms ± 437 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "59.1 ms ± 853 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "indexing...\n",
      "Wall time: 3.6 s\n",
      "\n",
      "with index\n",
      "229 µs ± 22.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "3.94 ms ± 19.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.65 ms ± 120 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "72.1 ms ± 2.01 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "76.8 ms ± 506 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "max_values = [10, 50, 100, 1000, 10000]\n",
    "X = 100000\n",
    "\n",
    "def get_query(max_value):\n",
    "    return '(value > %s) & (value <%s)' % (X, X+max_value)\n",
    "\n",
    "\n",
    "with tables.open_file(fn, \"a\") as f:\n",
    "    kv = f.root.keyvalues\n",
    "    #kv = f.root.sorted\n",
    "    \n",
    "    kv.cols.value.remove_index()\n",
    "\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        print('max_value=%d : len=%d' % (max_value, len(kv.read_where(query))))\n",
    "    \n",
    "    print('\\nwithout index:')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))\n",
    "\n",
    "    blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "    print('\\nindexing...')\n",
    "    %time kv.cols.value.create_csindex()\n",
    "\n",
    "    print('\\nwith index')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (Optional)\n",
    "\n",
    "Indexing queries with large result sets is difficult. `pytables` is not optimised for such queries. In general results are comparable to unindexed queries.\n",
    "\n",
    "For exterme performance, try an indexed query on a sorted table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tables.open_file(fn, 'a') as f:\n",
    "    table = f.root.keyvalues[:]\n",
    "    table.sort(order='value')\n",
    "    f.create_table('/', 'sorted', obj=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value=10 : len=24\n",
      "max_value=50 : len=95\n",
      "max_value=100 : len=206\n",
      "max_value=1000 : len=2061\n",
      "max_value=10000 : len=20102\n",
      "\n",
      "without index:\n",
      "44.5 ms ± 696 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "45.1 ms ± 216 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "43.9 ms ± 268 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "45.2 ms ± 536 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "46.6 ms ± 363 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "indexing...\n",
      "Wall time: 2.94 s\n",
      "\n",
      "with index\n",
      "188 µs ± 7.75 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "261 µs ± 9.06 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "421 µs ± 6.41 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.38 ms ± 30 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.58 ms ± 63.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "max_values = [10, 50, 100, 1000, 10000]\n",
    "X = 100000\n",
    "\n",
    "def get_query(max_value):\n",
    "    return '(value > %s) & (value <%s)' % (X, X+max_value)\n",
    "\n",
    "\n",
    "with tables.open_file(fn, \"a\") as f:\n",
    "    #kv = f.root.keyvalues\n",
    "    kv = f.root.sorted\n",
    "    \n",
    "    kv.cols.value.remove_index()\n",
    "\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        print('max_value=%d : len=%d' % (max_value, len(kv.read_where(query))))\n",
    "    \n",
    "    print('\\nwithout index:')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))\n",
    "\n",
    "    blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "    print('\\nindexing...')\n",
    "    %time kv.cols.value.create_csindex()\n",
    "\n",
    "    print('\\nwith index')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/keyvalues (Table(2000000,), shuffle, blosc(5)) ''\n",
      "  description := {\n",
      "  \"key\": StringCol(itemsize=10, shape=(), dflt=b' ', pos=0),\n",
      "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (3640,)\n",
      "  autoindex := True\n",
      "  colindexes := {\n",
      "    \"value\": Index(9, full, shuffle, zlib(1)).is_csi=True}\n",
      "/sorted (Table(2000000,)) ''\n",
      "  description := {\n",
      "  \"key\": StringCol(itemsize=10, shape=(), dflt=b'', pos=0),\n",
      "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (3640,)\n",
      "  autoindex := True\n",
      "  colindexes := {\n",
      "    \"value\": Index(9, full, shuffle, zlib(1)).is_csi=True}\n"
     ]
    }
   ],
   "source": [
    "!ptdump -v {fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hdf5]",
   "language": "python",
   "name": "conda-env-hdf5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
