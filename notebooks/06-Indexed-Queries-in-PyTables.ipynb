{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Indexed Queries in PyTables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    ">\n",
    "> * Learn how to index columns in tables for accelerating queries\n",
    "> * Experiment with different indexes and/or compression\n",
    "> * Discover some limitations of indexed queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing is a general technique for adding data structures that can accelerate queries.  Let's see how PyTables makes use of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalized case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the same datasets again, but we'll copy them, to add indexes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continue from the previous notebook\n",
    "data_dir = 'queries'\n",
    "h5denorm = \"compression/blosc-zstd-5-shuffle-denorm.h5\"\n",
    "h5norm = \"compression/blosc-zstd-5-shuffle.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queries\\\\movielens-denorm-indexed.h5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx = os.path.join(data_dir, \"movielens-denorm-indexed.h5\")\n",
    "if os.path.exists(h5idx):\n",
    "    os.unlink(h5idx)\n",
    "shutil.copyfile(h5denorm, h5idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx, mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the 'title' column\n",
    "h5lens = h5i.root.lens\n",
    "blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "%time h5lens.cols.title.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this time is 100x less than without using indexing.  What if we index the `rating` column too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 770 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the rating column\n",
    "%time h5lens.cols.rating.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.04 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so although small, this represents another improvement in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queries\\\\movielens-norm-indexed.h5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx = os.path.join(data_dir, \"movielens-norm-indexed.h5\")\n",
    "if os.path.exists(h5idx):\n",
    "    os.unlink(h5idx)\n",
    "shutil.copyfile(h5norm, h5idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx, mode=\"a\")\n",
    "h5ratings = h5i.root.ratings\n",
    "h5movies = h5i.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 577 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the rating column\n",
    "blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "%time h5ratings.cols.rating.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 436 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, in this case indexing the rating column has not served to accelerate the query (at first sight at least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 700 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the movie_id column\n",
    "%time h5ratings.cols.movie_id.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we see a better acceleration in the query, but cannot compete with the query speed for the denormalized case (which is ~10x faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20M\n",
      "-rw-r--r-- 1 tomkooij 197613 9.9M Jun 26 10:27 movielens-denorm-indexed.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 9.6M Jun 26 10:27 movielens-norm-indexed.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not created an index for the title for the normalized case.  Create such an index and determine if there is a noticeable speed-up or not.  Explain why you think that is the case.  Note: the times for a cold query can be **significatively** different from a hot query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movielens-norm-indexed2.h5'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx2 = \"movielens-norm-indexed2.h5\"\n",
    "if os.path.exists(h5idx2):\n",
    "    os.unlink(h5idx2)\n",
    "shutil.copyfile(h5idx, h5idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx2, mode=\"a\")\n",
    "h5ratings = h5i.root.ratings\n",
    "h5movies = h5i.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Solution starts here\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the movie_id column\n",
    "%time h5movies.cols.title.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So the first time that the query is done after the cache is built (cold query), the time has been reduced a bit but not too much.  For subsequent queries (hot queries), the times are better, but not reaching the denormalized table either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Query size vs speed (indexed queries vs non-indexed queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a (large) file containing some `(key, value)` pairs. The `value` is an `int64`. The `key` is a random 10-byte string, to simulate actual data, with normal compression.\n",
    "\n",
    "Investigate the query speed vs query result size. **Create the datafile first, the assignment is below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 20  # append 20 blocks of 1M rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block:  1\n",
      "block:  2\n",
      "block:  3\n",
      "block:  4\n",
      "block:  5\n",
      "block:  6\n",
      "block:  7\n",
      "block:  8\n",
      "block:  9\n",
      "block:  10\n",
      "block:  11\n",
      "block:  12\n",
      "block:  13\n",
      "block:  14\n",
      "block:  15\n",
      "block:  16\n",
      "block:  17\n",
      "block:  18\n",
      "block:  19\n",
      "block:  20\n"
     ]
    }
   ],
   "source": [
    "# adapted from: https://stackoverflow.com/questions/20769818/\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "class KeyValue(tables.IsDescription):\n",
    "    key = tables.StringCol(itemsize=10, dflt=\" \", pos=0)  \n",
    "    value = tables.Int64Col(dflt=0, pos=1)\n",
    "\n",
    "fn = os.path.join(data_dir, \"keyvalue.h5\")\n",
    "\n",
    "with tables.open_file(fn, \"w\") as f:    \n",
    "    filters = tables.Filters(complevel=5, complib='blosc')\n",
    "    kv = f.create_table(\"/\", \"keyvalues\", KeyValue, filters=filters)\n",
    "\n",
    "    for j in range(1, N+1):\n",
    "        values = []\n",
    "        print('block: ', j)\n",
    "        for _ in range(100000):\n",
    "            key = \"\".join(random.sample(string.ascii_uppercase, 10))  # slow!\n",
    "            value = random.randint(0, 1000000)\n",
    "            values.append((key, value))\n",
    "        kv.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/keyvalues (Table(2000000,), shuffle, blosc(5)) ''\n",
      "  description := {\n",
      "  \"key\": StringCol(itemsize=10, shape=(), dflt=b' ', pos=0),\n",
      "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (3640,)\n",
      "  Data dump:\n",
      "[0] (b'EIMUAQBPSZ', 671967)\n",
      "[1] (b'OIAWTMXSEN', 347907)\n",
      "[2] (b'EKWDBAFQSO', 718439)\n",
      "[3] (b'ZCEUWVIXYT', 180163)\n",
      "[4] (b'GHUCJAYXOB', 615020)\n",
      "[5] (b'MGQAXHJDVI', 421151)\n",
      "[6] (b'GPFLRWTNVA', 148149)\n",
      "[7] (b'TDKXBYULVR', 894572)\n",
      "[8] (b'QAORSBVIDC', 197511)\n",
      "[9] (b'JWXGUYTNZA', 276217)\n"
     ]
    }
   ],
   "source": [
    "!ptdump -v -R10 {fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Query the `value` column and compare different query (result) sizes:\n",
    "Compare indexed queries with unindexed queries.\n",
    "*Optional: compare different compression levels and codecs* \n",
    "\n",
    "\n",
    "For example: `'(value > 100000) & (value <1000010)'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Results start here\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value=10 : len=18\n",
      "max_value=50 : len=83\n",
      "max_value=100 : len=176\n",
      "max_value=1000 : len=1993\n",
      "max_value=10000 : len=19874\n",
      "\n",
      "read entire table:\n",
      "46.7 ms ± 4.93 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "without index:\n",
      "45.9 ms ± 7.87 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "51.2 ms ± 6.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "52.9 ms ± 5.75 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "47.3 ms ± 1.32 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "49 ms ± 798 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "indexing...\n",
      "Wall time: 3.25 s\n",
      "\n",
      "with index\n",
      "173 µs ± 14.6 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "3.42 ms ± 348 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.26 ms ± 308 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "59.9 ms ± 2.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "66.4 ms ± 3.69 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "max_values = [10, 50, 100, 1000, 10000]\n",
    "X = 100000\n",
    "\n",
    "def get_query(max_value):\n",
    "    return '(value > %s) & (value <%s)' % (X, X+max_value)\n",
    "\n",
    "\n",
    "with tables.open_file(fn, \"a\") as f:\n",
    "    kv = f.root.keyvalues\n",
    "    #kv = f.root.sorted\n",
    "    \n",
    "    kv.cols.value.remove_index()\n",
    "    \n",
    "    \n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        print('max_value=%d : len=%d' % (max_value, len(kv.read_where(query))))\n",
    "    \n",
    "    print('\\nread entire table:')\n",
    "    %timeit kv.read()\n",
    "    \n",
    "    print('\\nwithout index:')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))\n",
    "\n",
    "    blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "    print('\\nindexing...')\n",
    "    %time kv.cols.value.create_csindex()\n",
    "\n",
    "    print('\\nwith index')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (Optional)\n",
    "\n",
    "Indexing queries with large result sets is difficult. `pytables` is not optimised for such queries. In general results are comparable to unindexed queries (reading the entire table).\n",
    "\n",
    "For extreme performance, try an indexed query on a sorted table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tables.open_file(fn, 'a') as f:\n",
    "    table = f.root.keyvalues[:]\n",
    "    table.sort(order='value')\n",
    "    f.create_table('/', 'sorted', obj=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/keyvalues (Table(2000000,), shuffle, blosc(5)) ''\n",
      "  description := {\n",
      "  \"key\": StringCol(itemsize=10, shape=(), dflt=b' ', pos=0),\n",
      "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (3640,)\n",
      "  autoindex := True\n",
      "  colindexes := {\n",
      "    \"value\": Index(9, full, shuffle, zlib(1)).is_csi=True}\n",
      "/sorted (Table(2000000,)) ''\n",
      "  description := {\n",
      "  \"key\": StringCol(itemsize=10, shape=(), dflt=b'', pos=0),\n",
      "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (3640,)\n"
     ]
    }
   ],
   "source": [
    "!ptdump -v {fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value=10 : len=18\n",
      "max_value=50 : len=83\n",
      "max_value=100 : len=176\n",
      "max_value=1000 : len=1993\n",
      "max_value=10000 : len=19874\n",
      "\n",
      "read entire table:\n",
      "42.2 ms ± 1.13 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "without index:\n",
      "39.2 ms ± 4.52 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "37.1 ms ± 3.64 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "34.6 ms ± 711 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "34.6 ms ± 191 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "36 ms ± 336 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "indexing...\n",
      "Wall time: 2.5 s\n",
      "\n",
      "with index\n",
      "143 µs ± 380 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "212 µs ± 7.28 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "302 µs ± 1.39 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.06 ms ± 6.06 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "3.74 ms ± 5.19 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "max_values = [10, 50, 100, 1000, 10000]\n",
    "X = 100000\n",
    "\n",
    "def get_query(max_value):\n",
    "    return '(value > %s) & (value <%s)' % (X, X+max_value)\n",
    "\n",
    "\n",
    "with tables.open_file(fn, \"a\") as f:\n",
    "    #kv = f.root.keyvalues\n",
    "    kv = f.root.sorted\n",
    "    \n",
    "    kv.cols.value.remove_index()\n",
    "\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        print('max_value=%d : len=%d' % (max_value, len(kv.read_where(query))))\n",
    "    \n",
    "    print('\\nread entire table:')\n",
    "    %timeit kv.read()\n",
    "\n",
    "    print('\\nwithout index:')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))\n",
    "\n",
    "    blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "    print('\\nindexing...')\n",
    "    %time kv.cols.value.create_csindex()\n",
    "\n",
    "    print('\\nwith index')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hdf5]",
   "language": "python",
   "name": "conda-env-hdf5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
