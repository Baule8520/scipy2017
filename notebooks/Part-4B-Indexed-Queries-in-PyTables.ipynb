{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4B Indexed Queries in PyTables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    ">\n",
    "> * Learn how to index columns in tables for accelerating queries\n",
    "> * Experiment with different indexes and/or compression\n",
    "> * Discover some limitations of indexed queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing is a general technique for adding data structures that can accelerate queries.  Let's see how PyTables makes use of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalized case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continue from the previous notebook\n",
    "data_dir = 'queries'\n",
    "h5denorm = \"compression/blosc-zstd-5-shuffle-denorm.h5\"\n",
    "h5norm = \"compression/blosc-zstd-5-shuffle.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queries\\\\movielens-denorm-indexed.h5'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx = os.path.join(data_dir, \"movielens-denorm-indexed.h5\")\n",
    "if os.path.exists(h5idx):\n",
    "    os.unlink(h5idx)\n",
    "shutil.copyfile(h5denorm, h5idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx, mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the 'title' column\n",
    "h5lens = h5i.root.lens\n",
    "blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "%time h5lens.cols.title.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this time is 100x less than without using indexing.  What if we index the `rating` column too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 877 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the rating column\n",
    "%time h5lens.cols.rating.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so although small, this represents another improvement in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queries\\\\movielens-norm-indexed.h5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx = os.path.join(data_dir, \"movielens-norm-indexed.h5\")\n",
    "if os.path.exists(h5idx):\n",
    "    os.unlink(h5idx)\n",
    "shutil.copyfile(h5norm, h5idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx, mode=\"a\")\n",
    "h5ratings = h5i.root.ratings\n",
    "h5movies = h5i.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 671 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the rating column\n",
    "blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "%time h5ratings.cols.rating.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 457 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, in this case indexing the rating column has not served to accelerate the query (at first sight at least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 695 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the movie_id column\n",
    "%time h5ratings.cols.movie_id.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we see a better acceleration in the query, but cannot compete with the query speed for the denormalized case (which is ~10x faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20M\n",
      "-rw-r--r-- 1 tomkooij 197613 9.9M Jun 22 11:51 movielens-denorm-indexed.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 9.6M Jun 22 11:52 movielens-norm-indexed.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not created an index for the title for the normalized case.  Create such an index and determine if there is a noticeable speed-up or not.  Explain why you think that is the case.  Note: the times for a cold query can be **significatively** different from a hot query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movielens-norm-indexed2.h5'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx2 = \"movielens-norm-indexed2.h5\"\n",
    "if os.path.exists(h5idx2):\n",
    "    os.unlink(h5idx2)\n",
    "shutil.copyfile(h5idx, h5idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx2, mode=\"a\")\n",
    "h5ratings = h5i.root.ratings\n",
    "h5movies = h5i.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Solution starts here\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the movie_id column\n",
    "%time h5movies.cols.title.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 269 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So the first time that the query is done after the cache is built (cold query), the time has been reduced a bit but not too much.  For subsequent queries (hot queries), the times are better, but not reaching the denormalized table either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Query size vs speed (indexed queries vs non-indexed queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a (large) file containing some `(key, value)` pairs. The `value` is an `int64`. The `key` is a random 10-byte string, to simulate actual data, with normal compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 20  # append 20 blocks of 1M rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block:  1\n",
      "block:  2\n",
      "block:  3\n",
      "block:  4\n",
      "block:  5\n",
      "block:  6\n",
      "block:  7\n",
      "block:  8\n",
      "block:  9\n",
      "block:  10\n",
      "block:  11\n",
      "block:  12\n",
      "block:  13\n",
      "block:  14\n",
      "block:  15\n",
      "block:  16\n",
      "block:  17\n",
      "block:  18\n",
      "block:  19\n",
      "block:  20\n"
     ]
    }
   ],
   "source": [
    "# adapted from: https://stackoverflow.com/questions/20769818/\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "class KeyValue(tables.IsDescription):\n",
    "    key = tables.StringCol(itemsize=10, dflt=\" \", pos=0)  \n",
    "    value = tables.Int64Col(dflt=0, pos=1)\n",
    "\n",
    "fn = os.path.join(data_dir, \"keyvalue.h5\")\n",
    "\n",
    "with tables.open_file(fn, \"w\") as f:    \n",
    "    filters = tables.Filters(complevel=5, complib='blosc')\n",
    "    kv = f.create_table(\"/\", \"keyvalues\", KeyValue, filters=filters)\n",
    "\n",
    "    for j in range(1, N+1):\n",
    "        values = []\n",
    "        print('block: ', j)\n",
    "        for _ in range(100000):\n",
    "            key = \"\".join(random.sample(string.ascii_uppercase, 10))  # slow!\n",
    "            value = random.randint(0, 1000000)\n",
    "            values.append((key, value))\n",
    "        kv.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/keyvalues (Table(20000000,), shuffle, blosc(5)) ''\n",
      "  description := {\n",
      "  \"key\": StringCol(itemsize=30, shape=(), dflt=b' ', pos=0),\n",
      "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (1724,)\n",
      "  Data dump:\n",
      "[0] (b'QPGONRWHJX', 651797)\n",
      "[1] (b'HNGTUJYKAP', 313014)\n",
      "[2] (b'NRALQITYZV', 225736)\n",
      "[3] (b'YPLNGDVTHK', 210883)\n",
      "[4] (b'BXGIQLMFUE', 482386)\n",
      "[5] (b'OUSZQHPGFJ', 52527)\n",
      "[6] (b'GTZVRCMYNJ', 107035)\n",
      "[7] (b'CVAIYMLQHU', 92337)\n",
      "[8] (b'RYZCGWBTXL', 143533)\n",
      "[9] (b'HGOUALQSIC', 888223)\n"
     ]
    }
   ],
   "source": [
    "!ptdump -v -R10 {fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Query the `value` column and compare different query (result) sizes:\n",
    "Compare indexed queries with unindexed queries.\n",
    "*Optional: compare different compression levels and codecs* \n",
    "\n",
    "\n",
    "For example: `'(value > 100000) & (value <1000010)'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Results start here\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value=10 : len=16\n",
      "max_value=50 : len=105\n",
      "max_value=100 : len=189\n",
      "max_value=1000 : len=2048\n",
      "max_value=10000 : len=19787\n",
      "\n",
      "without index:\n",
      "41.5 ms ± 645 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "46.6 ms ± 3.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "51.7 ms ± 5.25 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "52 ms ± 7.15 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "50.9 ms ± 1.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "indexing...\n",
      "Wall time: 3.45 s\n",
      "\n",
      "with index\n",
      "179 µs ± 27.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.03 ms ± 218 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.24 ms ± 78.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "59.3 ms ± 559 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "66.9 ms ± 1.94 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "max_values = [10, 50, 100, 1000, 10000]\n",
    "X = 100000\n",
    "\n",
    "def get_query(max_value):\n",
    "    return '(value > %s) & (value <%s)' % (X, X+max_value)\n",
    "\n",
    "\n",
    "with tables.open_file(fn, \"a\") as f:\n",
    "    kv = f.root.keyvalues\n",
    "    #kv = f.root.sorted\n",
    "    \n",
    "    kv.cols.value.remove_index()\n",
    "\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        print('max_value=%d : len=%d' % (max_value, len(kv.read_where(query))))\n",
    "    \n",
    "    print('\\nwithout index:')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))\n",
    "\n",
    "    blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "    print('\\nindexing...')\n",
    "    %time kv.cols.value.create_csindex()\n",
    "\n",
    "    print('\\nwith index')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (Optional)\n",
    "\n",
    "Indexing queries with large result sets is difficult. `pytables` is not optimised for such queries. In general results are comparable to unindexed queries.\n",
    "\n",
    "For exterme performance, try an indexed query on a sorted table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tables.open_file(fn, 'a') as f:\n",
    "    table = f.root.keyvalues[:]\n",
    "    table.sort(order='value')\n",
    "    f.create_table('/', 'sorted', obj=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value=10 : len=16\n",
      "max_value=50 : len=105\n",
      "max_value=100 : len=189\n",
      "max_value=1000 : len=2048\n",
      "max_value=10000 : len=19787\n",
      "\n",
      "without index:\n",
      "38.4 ms ± 657 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "46.1 ms ± 5.56 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "46.8 ms ± 4.89 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "41.4 ms ± 4.09 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "41.5 ms ± 3.61 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "indexing...\n",
      "Wall time: 2.63 s\n",
      "\n",
      "with index\n",
      "168 µs ± 16.4 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "300 µs ± 48.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "367 µs ± 46.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.14 ms ± 20.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.37 ms ± 544 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "max_values = [10, 50, 100, 1000, 10000]\n",
    "X = 100000\n",
    "\n",
    "def get_query(max_value):\n",
    "    return '(value > %s) & (value <%s)' % (X, X+max_value)\n",
    "\n",
    "\n",
    "with tables.open_file(fn, \"a\") as f:\n",
    "    #kv = f.root.keyvalues\n",
    "    kv = f.root.sorted\n",
    "    \n",
    "    kv.cols.value.remove_index()\n",
    "\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        print('max_value=%d : len=%d' % (max_value, len(kv.read_where(query))))\n",
    "    \n",
    "    print('\\nwithout index:')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))\n",
    "\n",
    "    blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "    print('\\nindexing...')\n",
    "    %time kv.cols.value.create_csindex()\n",
    "\n",
    "    print('\\nwith index')\n",
    "    for max_value in max_values:\n",
    "        query = get_query(max_value)\n",
    "        %timeit sum(1 for x in kv.where(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hdf5]",
   "language": "python",
   "name": "conda-env-hdf5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
