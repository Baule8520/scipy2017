{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3B Using compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    "> * How to compress chunked datasets\n",
    "> * Learn how to fine-tune the HDF5 compression pipeline to suit your needs\n",
    "> * How to use pandas for reading CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "data_dir = \"compression\"\n",
    "if os.path.exists(data_dir):\n",
    "    shutil.rmtree(data_dir)\n",
    "os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermezzo: the movielens-1M datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous work by Greg Reda: http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/\n",
    "\n",
    "This dataset describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. These files contain 1,000,209 anonymous ratings of approximately 3,900 movies  made by 6,040 MovieLens users who joined MovieLens in 2000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import CSV files via pandas\n",
    "dset = 'datasets\\movielens-1m'\n",
    "fdata = os.path.join(dset, 'ratings.dat.gz')\n",
    "fitem = os.path.join(dset, 'movies.dat.gz')\n",
    "\n",
    "# pass in column names for each CSV\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(fdata, sep=';', names=r_cols)\n",
    "\n",
    "m_cols = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_csv(fitem, sep=';', names=m_cols,\n",
    "                     dtype={'title': object, 'genres': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                               title                        genres\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3883 entries, 0 to 3882\n",
      "Data columns (total 3 columns):\n",
      "movie_id    3883 non-null int64\n",
      "title       3883 non-null object\n",
      "genres      3883 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 91.1+ KB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id     int64:dense\n",
       "title       object:dense\n",
       "genres      object:dense\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.ftypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  unix_timestamp\n",
       "0        1      1193       5       978300760\n",
       "1        1       661       3       978302109\n",
       "2        1       914       3       978301968\n",
       "3        1      3408       4       978300275\n",
       "4        1      2355       5       978824291"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           int64:dense\n",
       "movie_id          int64:dense\n",
       "rating            int64:dense\n",
       "unix_timestamp    int64:dense\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.ftypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing in HDF5/PyTables in compressed form\n",
    "\n",
    "We enable compression by using the HDF5 Filters. These are accessed in `pytables` using the `tables.Filters` class:\n",
    "\n",
    "```\n",
    "filters = tables.Filters(complevel=2, complib='zlib')\n",
    "f.create_table(..., filters=filters)\n",
    "```\n",
    "\n",
    "`table.Filters()` kwargs:\n",
    "\n",
    "* `complevel`\n",
    "    compression level (`complevel`): 0 (no compression) to 9 (maximum compression) \n",
    "\n",
    "* `complib` compression libraries:\n",
    "  - **zlib** (standard HDF5)\n",
    "  - **lzo** (usually not available) \n",
    "  - **bzip2**\n",
    "  - **BLOSC**\n",
    "      - blosc:blosclz\n",
    "      - blosc:lz4\n",
    "      - blosc:lz4hc\n",
    "      - blosc:snappy\n",
    "      - blosc:zlib\n",
    "      - blosc:zstd\n",
    "* `shuffle` use shuffle filter \n",
    "\n",
    "---------\n",
    "\n",
    "`to_hdf5` creates a HDF5 with the Movielens dataset with a filename corresponding to the `Filters` settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_hdf5(ratings, movies, filters):\n",
    "    \n",
    "    class Ratings(tables.IsDescription):\n",
    "        user_id = tables.Int32Col(pos=0)\n",
    "        movie_id = tables.Int32Col(pos=1)\n",
    "        rating = tables.Int8Col(pos=2)\n",
    "        unix_timestamp = tables.Int64Col(pos=3)\n",
    "    \n",
    "    class Movies(tables.IsDescription):\n",
    "        movie_id = tables.Int32Col(pos=0)\n",
    "        title = tables.StringCol(100, pos=1)\n",
    "        genres = tables.StringCol(50, pos=2)\n",
    "    \n",
    "    def get_filename(filters):\n",
    "        if filters.complevel != 0:\n",
    "            complib = filters.complib if \":\" not in filters.complib else filters.complib.replace(\":\", \"-\")\n",
    "            shuffle = \"shuffle\" if filters.shuffle else \"noshuffle\"\n",
    "            filename = \"%s/%s-%d-%s.h5\" % (data_dir, complib, filters.complevel, shuffle)\n",
    "        else:\n",
    "            filename = \"%s/no-compression.h5\" % (data_dir,)\n",
    "        return filename\n",
    "\n",
    "    filename = get_filename(filters)\n",
    "    print(\"Creating file:\", filename)\n",
    "    with tables.open_file(filename, \"w\") as f:\n",
    "        table_ratings = f.create_table(f.root, \"ratings\", Ratings, filters=filters, expectedrows=len(ratings))\n",
    "        table_ratings.append([ratings[col].values for col in ratings.ftypes.keys()])\n",
    "        table_movies = f.create_table(f.root, \"movies\", Movies, filters=filters, expectedrows=len(movies))\n",
    "        table_movies.append([movies[col].values for col in movies.ftypes.keys()])\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/zlib-5-shuffle.h5\n",
      "Wall time: 678 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filters = tables.Filters(complevel=5)\n",
    "h5file = to_hdf5(ratings, movies, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/movies (Table(3883,), shuffle, zlib(5)) ''\n",
      "  description := {\n",
      "  \"movie_id\": Int32Col(shape=(), dflt=0, pos=0),\n",
      "  \"title\": StringCol(itemsize=100, shape=(), dflt=b'', pos=1),\n",
      "  \"genres\": StringCol(itemsize=50, shape=(), dflt=b'', pos=2)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (425,)\n",
      "/ratings (Table(1000209,), shuffle, zlib(5)) ''\n",
      "  description := {\n",
      "  \"user_id\": Int32Col(shape=(), dflt=0, pos=0),\n",
      "  \"movie_id\": Int32Col(shape=(), dflt=0, pos=1),\n",
      "  \"rating\": Int8Col(shape=(), dflt=0, pos=2),\n",
      "  \"unix_timestamp\": Int64Col(shape=(), dflt=0, pos=3)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (7710,)\n"
     ]
    }
   ],
   "source": [
    "!ptdump -v {h5file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Compression. Create/write speed.\n",
    "\n",
    "PyTables comes with out-of-box support for a series of codecs.  Do a quick comparison between \"zlib\", \"bzip2\", and \"blosc\" for compression levels of 1 (fastest), 5 and 9 (slowest).  Which one compresses best?  Which one compresses faster?\n",
    "\n",
    "Also, Blosc being a meta-compressor, it has support for different codecs internally that can be selected from PyTables in the \"blosc:`codec`\" form.  Do another comparison between internal Blosc codecs, namely, \"blosc:blosclz\" (the default), \"blosc:lz4\", \"blosc:lz4hc\", \"blosc:snappy\", \"blosc:zlib\" and \"blosc:zstd\".\n",
    "\n",
    "Finally, avoid any compression totally (`complevel=0`).  How fast it is compared with existing codecs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# SOLUTION STARTS HERE\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/zlib-5-shuffle.h5\n",
      "Wall time: 648 ms\n",
      "Creating file: compression/bzip2-5-shuffle.h5\n",
      "Wall time: 1.46 s\n",
      "Creating file: compression/blosc-5-shuffle.h5\n",
      "Wall time: 163 ms\n"
     ]
    }
   ],
   "source": [
    "for complib in (\"zlib\", \"bzip2\", \"blosc\"):\n",
    "    filters = tables.Filters(complevel=5, complib=complib)\n",
    "    %time to_hdf5(ratings, movies, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14M\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.1M Jun 22 11:31 bzip2-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:31 zlib-5-shuffle.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/blosc-blosclz-5-shuffle.h5\n",
      "Wall time: 173 ms\n",
      "Creating file: compression/blosc-lz4-5-shuffle.h5\n",
      "Wall time: 115 ms\n",
      "Creating file: compression/blosc-lz4hc-5-shuffle.h5\n",
      "Wall time: 347 ms\n",
      "Creating file: compression/blosc-snappy-5-shuffle.h5\n",
      "Wall time: 132 ms\n",
      "Creating file: compression/blosc-zlib-5-shuffle.h5\n",
      "Wall time: 638 ms\n",
      "Creating file: compression/blosc-zstd-5-shuffle.h5\n",
      "Wall time: 448 ms\n"
     ]
    }
   ],
   "source": [
    "for complib in (\"blosc:blosclz\", \"blosc:lz4\", \"blosc:lz4hc\", \"blosc:snappy\", \"blosc:zlib\", \"blosc:zstd\"):\n",
    "    filters = tables.Filters(complevel=5, complib=complib)\n",
    "    %time to_hdf5(ratings, movies, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/no-compression.h5\n",
      "Wall time: 93.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'compression/no-compression.h5'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, the uncompressed case\n",
    "filters = tables.Filters(complevel=0)\n",
    "%time to_hdf5(ratings, movies, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 60M\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-blosclz-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.4M Jun 22 11:31 blosc-lz4-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.8M Jun 22 11:31 blosc-lz4hc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.5M Jun 22 11:32 blosc-snappy-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.4M Jun 22 11:32 blosc-zlib-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:32 blosc-zstd-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.1M Jun 22 11:31 bzip2-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613  17M Jun 22 11:32 no-compression.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:31 zlib-5-shuffle.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading compressed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = list(os.walk(data_dir))[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blosc-5-shuffle.h5',\n",
       " 'blosc-blosclz-5-shuffle.h5',\n",
       " 'blosc-lz4-5-shuffle.h5',\n",
       " 'blosc-lz4hc-5-shuffle.h5',\n",
       " 'blosc-snappy-5-shuffle.h5',\n",
       " 'blosc-zlib-5-shuffle.h5',\n",
       " 'blosc-zstd-5-shuffle.h5',\n",
       " 'bzip2-5-shuffle.h5',\n",
       " 'no-compression.h5',\n",
       " 'zlib-5-shuffle.h5']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Reading compressed datasets\n",
    "\n",
    "Which codec and compression level can read the fastest?  How it does compare with reading an uncompressed dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# SOLUTION STARTS HERE\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: blosc-5-shuffle.h5\n",
      "40.3 ms ± 234 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-blosclz-5-shuffle.h5\n",
      "40.8 ms ± 636 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-lz4-5-shuffle.h5\n",
      "31.2 ms ± 149 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-lz4hc-5-shuffle.h5\n",
      "31.7 ms ± 257 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-snappy-5-shuffle.h5\n",
      "39.3 ms ± 83.3 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-zlib-5-shuffle.h5\n",
      "106 ms ± 132 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-zstd-5-shuffle.h5\n",
      "57.9 ms ± 394 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: bzip2-5-shuffle.h5\n",
      "548 ms ± 11.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Reading file: no-compression.h5\n",
      "18.1 ms ± 46.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Reading file: zlib-5-shuffle.h5\n",
      "123 ms ± 13.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    print(\"Reading file:\", f)\n",
    "    with tables.open_file(os.path.join(data_dir, f)) as h5f:\n",
    "        %timeit h5f.root.ratings[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: BLOSC multithreading\n",
    "\n",
    "Blosc can use multithreading for compressing/decompressing, although it is disabled by default.  You can enable a multithreaded Blosc in a series of ways, but perhaps the easiest is to set the \"BLOSC_NTHREADS\" environment variable to the desired number of threads (typically the available number of cores in your computer).\n",
    "\n",
    "Execute the cell below and re-do the reading benchmarks and look at how the reading speed vary.  Pay special attention to the difference between the CPU times and wall times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"BLOSC_NTHREADS\"] = \"4\"  # set to any other number you prefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# SOLUTION STARTS HERE\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: blosc-5-shuffle.h5 nthreads= 1\n",
      "48.6 ms ± 2.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-5-shuffle.h5 nthreads= 2\n",
      "45.7 ms ± 2.81 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-5-shuffle.h5 nthreads= 4\n",
      "39.8 ms ± 2.96 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-blosclz-5-shuffle.h5 nthreads= 1\n",
      "44.5 ms ± 5.96 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-blosclz-5-shuffle.h5 nthreads= 2\n",
      "50 ms ± 4.44 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-blosclz-5-shuffle.h5 nthreads= 4\n",
      "48.6 ms ± 5.71 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-lz4-5-shuffle.h5 nthreads= 1\n",
      "33.1 ms ± 2.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-lz4-5-shuffle.h5 nthreads= 2\n",
      "35.3 ms ± 2.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-lz4-5-shuffle.h5 nthreads= 4\n",
      "38.7 ms ± 4.69 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-lz4hc-5-shuffle.h5 nthreads= 1\n",
      "35.2 ms ± 4.22 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-lz4hc-5-shuffle.h5 nthreads= 2\n",
      "29.6 ms ± 1.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-lz4hc-5-shuffle.h5 nthreads= 4\n",
      "38.8 ms ± 4.91 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-snappy-5-shuffle.h5 nthreads= 1\n",
      "42.5 ms ± 2.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-snappy-5-shuffle.h5 nthreads= 2\n",
      "41 ms ± 164 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-snappy-5-shuffle.h5 nthreads= 4\n",
      "37.9 ms ± 124 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-zlib-5-shuffle.h5 nthreads= 1\n",
      "110 ms ± 5.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-zlib-5-shuffle.h5 nthreads= 2\n",
      "73.6 ms ± 7.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-zlib-5-shuffle.h5 nthreads= 4\n",
      "76.8 ms ± 3.23 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-zstd-5-shuffle.h5 nthreads= 1\n",
      "58.6 ms ± 409 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-zstd-5-shuffle.h5 nthreads= 2\n",
      "52.8 ms ± 8.18 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: blosc-zstd-5-shuffle.h5 nthreads= 4\n",
      "49.6 ms ± 472 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: bzip2-5-shuffle.h5 nthreads= 1\n",
      "543 ms ± 706 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Reading file: bzip2-5-shuffle.h5 nthreads= 2\n",
      "543 ms ± 2.82 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Reading file: bzip2-5-shuffle.h5 nthreads= 4\n",
      "555 ms ± 27.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Reading file: no-compression.h5 nthreads= 1\n",
      "18.9 ms ± 622 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Reading file: no-compression.h5 nthreads= 2\n",
      "18.5 ms ± 249 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Reading file: no-compression.h5 nthreads= 4\n",
      "19.6 ms ± 1.35 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Reading file: zlib-5-shuffle.h5 nthreads= 1\n",
      "114 ms ± 298 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: zlib-5-shuffle.h5 nthreads= 2\n",
      "117 ms ± 3.78 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Reading file: zlib-5-shuffle.h5 nthreads= 4\n",
      "114 ms ± 246 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    for nthreads in [1, 2, 4]:\n",
    "        os.environ[\"BLOSC_NTHREADS\"] = \"%s\" % nthreads\n",
    "        print(\"Reading file:\", f, 'nthreads=', os.environ[\"BLOSC_NTHREADS\"])\n",
    "        with tables.open_file(os.path.join(data_dir, f)) as h5f:\n",
    "            %timeit h5f.root.ratings[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing and denormalizing tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many data sources are expressed in terms of related tables.  For example, part of the [MovieLens dataset](https://grouplens.org/datasets/movielens/) is structured in tables having the next columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "movies = ['movie_id', 'title', 'genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation that links the two tables above is the `movie_id` field.  This way, one can query parts of the dataset that involve the two tables, like for example, which users ('user_id') gave a rating of 5 to some movie ('title').  This is called the `normalized` version and we have already dealt with that in a previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, one can fuse the above 2 tables into a single one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_movies = ['title', 'genres', 'user_id', 'rating', 'unix_timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, we still keep all the data fields, except for the 'movie_id' that is not needed anymore.  This is called the `denormalized` version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of this one is that we have all the fields readily available in one single table, so querying it and getting info about all the fileds is straighforward.  The disadvantage is that this table will have many duplicated information, i.e. the 'title' and 'genres' fields will appear for all the ratings, which can be seen as a waste of space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, many times compression can get rid of many of the duplicated info in denormalized tables.  Let's see how to produce a denormalized table and how it fares compared with the normalized version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Denormalizing tables using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import CSV files via pandas\n",
    "dset = 'datasets\\movielens-1m'\n",
    "fdata = os.path.join(dset, 'ratings.dat.gz')\n",
    "fitem = os.path.join(dset, 'movies.dat.gz')\n",
    "\n",
    "# pass in column names for each CSV\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(fdata, sep=';', names=r_cols)\n",
    "\n",
    "m_cols = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_csv(fitem, sep=';', names=m_cols,\n",
    "                     dtype={'title': object, 'genres': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create one merged DataFrame\n",
    "lens = pd.merge(movies, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>978237008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>978233496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>978225952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>978226474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id             title                       genres  user_id  rating  \\\n",
       "0         1  Toy Story (1995)  Animation|Children's|Comedy        1       5   \n",
       "1         1  Toy Story (1995)  Animation|Children's|Comedy        6       4   \n",
       "2         1  Toy Story (1995)  Animation|Children's|Comedy        8       4   \n",
       "3         1  Toy Story (1995)  Animation|Children's|Comedy        9       5   \n",
       "4         1  Toy Story (1995)  Animation|Children's|Comedy       10       5   \n",
       "\n",
       "   unix_timestamp  \n",
       "0       978824268  \n",
       "1       978237008  \n",
       "2       978233496  \n",
       "3       978225952  \n",
       "4       978226474  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id           int64:dense\n",
       "title             object:dense\n",
       "genres            object:dense\n",
       "user_id            int64:dense\n",
       "rating             int64:dense\n",
       "unix_timestamp     int64:dense\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.ftypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_hdf5_denorm(lens, filters):\n",
    "\n",
    "    class Lens(tables.IsDescription):\n",
    "        user_id = tables.Int32Col(pos=0)\n",
    "        rating = tables.Int8Col(pos=1)\n",
    "        unix_timestamp = tables.Int64Col(pos=2)\n",
    "        title = tables.StringCol(100, pos=3)\n",
    "        genres = tables.StringCol(50, pos=4)\n",
    "        \n",
    "    def get_filename(filters):\n",
    "        if filters.complevel != 0:\n",
    "            complib = filters.complib if \":\" not in filters.complib else filters.complib.replace(\":\", \"-\")\n",
    "            shuffle = \"shuffle\" if filters.shuffle else \"noshuffle\"\n",
    "            filename = \"%s/%s-%d-%s-denorm.h5\" % (data_dir, complib, filters.complevel, shuffle)\n",
    "        else:\n",
    "            filename = \"%s/no-compression-denorm.h5\" % (data_dir,)\n",
    "        return filename\n",
    "\n",
    "    filename = get_filename(filters)\n",
    "    print(\"Creating file:\", filename)\n",
    "    with tables.open_file(filename, \"w\", filters=filters) as f:\n",
    "        table_lens = f.create_table(f.root, \"lens\", Lens)\n",
    "        table_lens.append([lens[col].values for col in table_lens.dtype.names])\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/no-compression-denorm.h5\n",
      "Wall time: 492 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filters = tables.Filters(complevel=0)\n",
    "h5file = to_hdf5_denorm(lens, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/lens (Table(1000209,)) ''\n",
      "  description := {\n",
      "  \"user_id\": Int32Col(shape=(), dflt=0, pos=0),\n",
      "  \"rating\": Int8Col(shape=(), dflt=0, pos=1),\n",
      "  \"unix_timestamp\": Int64Col(shape=(), dflt=0, pos=2),\n",
      "  \"title\": StringCol(itemsize=100, shape=(), dflt=b'', pos=3),\n",
      "  \"genres\": StringCol(itemsize=50, shape=(), dflt=b'', pos=4)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (402,)\n",
      "  Data dump:\n",
      "[0] (1, 5, 978824268, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[1] (6, 4, 978237008, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[2] (8, 4, 978233496, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[3] (9, 5, 978225952, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[4] (10, 5, 978226474, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[5] (18, 4, 978154768, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[6] (19, 5, 978555994, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[7] (21, 3, 978139347, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[8] (23, 4, 978463614, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n",
      "[9] (26, 3, 978130703, b'Toy Story (1995)', b\"Animation|Children's|Comedy\")\n"
     ]
    }
   ],
   "source": [
    "!ptdump -v -R0,10 {h5file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 215M\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-blosclz-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.4M Jun 22 11:31 blosc-lz4-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.8M Jun 22 11:31 blosc-lz4hc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.5M Jun 22 11:32 blosc-snappy-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.4M Jun 22 11:32 blosc-zlib-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:32 blosc-zstd-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.1M Jun 22 11:31 bzip2-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 156M Jun 22 11:35 no-compression-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613  17M Jun 22 11:32 no-compression.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:31 zlib-5-shuffle.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the size of the denormalized table is much larger than the normalized one (156 MB vs 17 MB).  But that is without using compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Compressing a denormalized table\n",
    "\n",
    "Create a compressed version of the denormalized table and compare it with the same table in the normalized state.\n",
    "What's the difference in size now?  Why do you think the compression process works much better in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# SOLUTION STARTS HERE\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/blosc-blosclz-5-shuffle-denorm.h5\n",
      "Wall time: 806 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'compression/blosc-blosclz-5-shuffle-denorm.h5'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = tables.Filters(complevel=5, complib=\"blosc:blosclz\")\n",
    "%time to_hdf5_denorm(lens, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 223M\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 7.3M Jun 22 11:35 blosc-blosclz-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-blosclz-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.4M Jun 22 11:31 blosc-lz4-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.8M Jun 22 11:31 blosc-lz4hc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.5M Jun 22 11:32 blosc-snappy-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.4M Jun 22 11:32 blosc-zlib-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:32 blosc-zstd-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.1M Jun 22 11:31 bzip2-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 156M Jun 22 11:35 no-compression-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613  17M Jun 22 11:32 no-compression.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:31 zlib-5-shuffle.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Denormalized table: compare codecs.\n",
    "\n",
    "Create different files containing the denormalized table using different codecs.  Which one reduces the size better?  How does it compare with the files for the normalized version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/zlib-5-shuffle-denorm.h5\n",
      "Wall time: 2.34 s\n",
      "Creating file: compression/bzip2-5-shuffle-denorm.h5\n",
      "Wall time: 6.45 s\n",
      "Creating file: compression/blosc-blosclz-5-shuffle-denorm.h5\n",
      "Wall time: 801 ms\n",
      "Creating file: compression/blosc-lz4-5-shuffle-denorm.h5\n",
      "Wall time: 770 ms\n",
      "Creating file: compression/blosc-lz4hc-5-shuffle-denorm.h5\n",
      "Wall time: 1.42 s\n",
      "Creating file: compression/blosc-snappy-5-shuffle-denorm.h5\n",
      "Wall time: 807 ms\n",
      "Creating file: compression/blosc-zlib-5-shuffle-denorm.h5\n",
      "Wall time: 2.51 s\n",
      "Creating file: compression/blosc-zstd-5-shuffle-denorm.h5\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "for complib in (\"zlib\", \"bzip2\", \"blosc:blosclz\", \"blosc:lz4\", \"blosc:lz4hc\", \"blosc:snappy\", \"blosc:zlib\", \"blosc:zstd\"):\n",
    "    filters = tables.Filters(complevel=5, complib=complib)\n",
    "    %time to_hdf5_denorm(lens, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 417M\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 7.3M Jun 22 11:36 blosc-blosclz-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 22 11:31 blosc-blosclz-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 7.8M Jun 22 11:36 blosc-lz4-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.4M Jun 22 11:31 blosc-lz4-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 6.7M Jun 22 11:36 blosc-lz4hc-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.8M Jun 22 11:31 blosc-lz4hc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 156M Jun 22 11:36 blosc-snappy-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.5M Jun 22 11:32 blosc-snappy-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 6.1M Jun 22 11:36 blosc-zlib-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.4M Jun 22 11:32 blosc-zlib-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.5M Jun 22 11:36 blosc-zstd-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:32 blosc-zstd-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 6.4M Jun 22 11:36 bzip2-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.1M Jun 22 11:31 bzip2-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 156M Jun 22 11:35 no-compression-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613  17M Jun 22 11:32 no-compression.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 6.0M Jun 22 11:35 zlib-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 22 11:31 zlib-5-shuffle.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section we will see the effect of querying normalized and denormalized tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hdf5]",
   "language": "python",
   "name": "conda-env-hdf5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
