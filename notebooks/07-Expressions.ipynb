{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Expressions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tables.Expr` class evaluates (in-kernel) expressions on array-like objects. All the internal computations are performed via the `Numexpr` package. `Numexpr` provides multi-threading, SIMD and blocking techniques to solve the starving CPU problem. In combination with compressors (blosc) very high out-of-core performance can be reached for expressions on large-than-memory arrays (tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tables\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'expr'\n",
    "import os\n",
    "import shutil\n",
    "if os.path.exists(data_dir):\n",
    "    shutil.rmtree(data_dir)\n",
    "os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a table with four columns (four-momentum from particle physics) and store random floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILENAME = os.path.join(data_dir, \"momentum.h5\")\n",
    "f = tables.open_file(FILENAME, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FourMomentum(tables.IsDescription): \n",
    "    E = tables.Float64Col()\n",
    "    p_x = tables.Float64Col()\n",
    "    p_y = tables.Float64Col()\n",
    "    p_z = tables.Float64Col() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters = tables.Filters(complevel=0)  # no compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = f.create_table(f.root, \"mydata\", FourMomentum, filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store 1 million rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 0.65621637,  0.65621637,  0.65621637,  0.65621637),\n",
       "       ( 0.33005409,  0.33005409,  0.33005409,  0.33005409)],\n",
       "      dtype=[('E', '<f8'), ('p_x', '<f8'), ('p_y', '<f8'), ('p_z', '<f8')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.random.random((N,)).astype(dtype)\n",
    "arr[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65621637,  0.33005409,  0.59829078,  0.33769868,  0.77929896,\n",
       "        0.35366154,  0.04231687,  0.85648859,  0.42816492,  0.22218853])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:10]['p_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can acccess the columns using the `Cols` accessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "px = t.cols.p_x\n",
    "py = t.cols.p_y\n",
    "pz = t.cols.p_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tables.expression.Expr at 0x2003062ab70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr = tables.Expr('px**2 + py**2 + pz**2')\n",
    "expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the expression, result will be stored in-memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.8 ms ± 635 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit expr.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the pure-numpy version of the expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.3 ms ± 3.01 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit arr['p_x']**2 + arr['p_y']**2 + arr['p_z']**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example numpy is 2-3x times faster. For large, in-memory arrays, pure numpy is usually about 1.5x faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### out-of-core\n",
    "\n",
    "We can store results on-disk (in HDF5) so we can evaluate expressions out-of-core even if the results do not fit into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/output (CArray(1000000,)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (8192,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array = f.create_carray(f.root, \"output\", atom=tables.Float64Atom(), shape=(N,), filters=filters)\n",
    "output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expr.set_output(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.1 ms ± 773 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit expr.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.29185977,  0.3268071 ,  1.07385558, ...,  0.87298304,\n",
       "        2.27123376,  0.73753768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.root.output[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way we can evaluate expressions with larger-than-memory results out-of-core. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using compression\n",
    "\n",
    "The facilitate experimenting with dataset size, compression etc, we define some functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = os.path.join(data_dir, 'momentum.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(N, filename, filters):\n",
    "    \"\"\"Create table '/mydata' with a random four-momentum table of size N\"\"\"\n",
    "    with tables.open_file(filename, \"w\") as f:\n",
    "\n",
    "        t = f.create_table(f.root, \"mydata\", FourMomentum, filters=filters)\n",
    "\n",
    "        dtype = t.dtype\n",
    "        arr = np.random.random((N,)).astype(dtype)\n",
    "        t.append(arr)\n",
    "        t.flush()\n",
    "\n",
    "        f.create_carray(f.root, \"output\", atom=tables.Float64Atom(), shape=(N,), filters=filters)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_expression(f, output=None, expr='px**2 + py**2 + pz**2'):\n",
    "    \"\"\"Create an expression object\"\"\"\n",
    "    t = f.root.mydata\n",
    "    px = t.cols.p_x\n",
    "    py = t.cols.p_y\n",
    "    pz = t.cols.p_z\n",
    "\n",
    "    e = tables.Expr(expr)\n",
    "    if output is not None:\n",
    "        e.set_output(output)\n",
    "    return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters = tables.Filters(complevel=0)\n",
    "fn = os.path.join(data_dir, 'momentum-uncompressed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N=int(1e7)  # N == 1e7 is about 300 Mbytes.\n",
    "create_dataset(N, fn, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 484M\n",
      "-rw-r--r-- 1 tomkooij 197613 140M Jun 26 12:02 momentum-blosc-lz4.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 306M Jun 26 12:02 momentum-uncompressed.h5\n",
      "-rw-r--r-- 1 tomkooij 197613  39M Jun 26 11:58 momentum.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 ms ± 59.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "with tables.open_file(fn, 'a') as f:\n",
    "    expr = create_expression(f)\n",
    "    %timeit expr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988 ms ± 79.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "with tables.open_file(fn, 'a') as f:\n",
    "    expr = create_expression(f, output=f.root.output)\n",
    "    %timeit expr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 560M\n",
      "-rw-r--r-- 1 tomkooij 197613 140M Jun 26 12:02 momentum-blosc-lz4.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 382M Jun 26 12:02 momentum-uncompressed.h5\n",
      "-rw-r--r-- 1 tomkooij 197613  39M Jun 26 11:58 momentum.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Create an (reasonably) compressible dataset and investigate the `tables.Expr` performance with and without compression. \n",
    "\n",
    "Can you achieve reasonable perfomance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Solution starts here\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters = tables.Filters(complevel=6, complib='blosc:lz4')\n",
    "fn = os.path.join(data_dir, 'momentum-blosc-lz4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N=int(1e7)  \n",
    "create_dataset(N, fn, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 413M\n",
      "-rw-r--r-- 1 tomkooij 197613  69M Jun 26 12:01 momentum-blosc-lz4.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 306M Jun 26 12:01 momentum-uncompressed.h5\n",
      "-rw-r--r-- 1 tomkooij 197613  39M Jun 26 11:58 momentum.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32 s ± 50.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "with tables.open_file(fn, 'a') as f:\n",
    "    expr = create_expression(f, output=f.root.output)\n",
    "    %timeit expr.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general in HDF5 a compressed dataset performs slightly slower than the uncompressed dataset. This is somewhat disappointing as there are very efficient datacontairs (`bcolz`) which do achieve better compressed read/write performance.\n",
    "\n",
    "However, in general, we can use compressors to give us very good compression, with only a slight read/write penalty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hdf5]",
   "language": "python",
   "name": "conda-env-hdf5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
