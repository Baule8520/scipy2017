{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4A Queries in PyTables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    "> * Query HDF5 files without loading them in-memory\n",
    "> * How to query normalized and denormalized tables\n",
    "> * Index columns in tables for accelerating queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "data_dir = \"queries\"\n",
    "if os.path.exists(data_dir):\n",
    "    shutil.rmtree(data_dir)\n",
    "os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 406M\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 19 14:48 blosc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 7.3M Jun 19 14:48 blosc-blosclz-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.0M Jun 19 14:48 blosc-blosclz-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 7.8M Jun 19 14:48 blosc-lz4-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.4M Jun 19 14:48 blosc-lz4-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 6.7M Jun 19 14:48 blosc-lz4hc-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.8M Jun 19 14:48 blosc-lz4hc-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 156M Jun 19 14:48 blosc-snappy-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.5M Jun 19 14:48 blosc-snappy-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 6.1M Jun 19 14:48 blosc-zlib-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.4M Jun 19 14:48 blosc-zlib-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 5.5M Jun 19 14:48 blosc-zstd-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 19 14:48 blosc-zstd-5-shuffle.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 156M Jun 19 14:48 no-compression-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613  17M Jun 19 14:48 no-compression.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 6.0M Jun 19 14:48 zlib-5-shuffle-denorm.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 4.3M Jun 19 14:48 zlib-5-shuffle.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying in PyTables\n",
    "\n",
    "Searching in tables is one of the most common and time consuming operations that a typical user faces in the process of mining through his data. Being able to perform queries as fast as possible is a key concept in data usage applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Movieslens-1M (denormalized) not compressed:\n",
    "fn = \"compression/no-compression-denorm.h5\"\n",
    "h5file = tables.open_file(fn)\n",
    "table = h5file.root.lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_where()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`table.read_where()` reads all table rows that match a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 5, 978824268, b'Toy Story (1995)', b\"Animation|Children's|Comedy\"),\n",
       "       (6, 4, 978237008, b'Toy Story (1995)', b\"Animation|Children's|Comedy\"),\n",
       "       (8, 4, 978233496, b'Toy Story (1995)', b\"Animation|Children's|Comedy\"),\n",
       "       ...,\n",
       "       (5812, 4, 992072099, b'Contender, The (2000)', b'Drama|Thriller'),\n",
       "       (5837, 4, 1011902656, b'Contender, The (2000)', b'Drama|Thriller'),\n",
       "       (5998, 4, 1001781044, b'Contender, The (2000)', b'Drama|Thriller')], \n",
       "      dtype=[('user_id', '<i4'), ('rating', 'i1'), ('unix_timestamp', '<i8'), ('title', 'S100'), ('genres', 'S50')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.read_where(\"rating >= 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43 s ± 25.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = table.read_where(\"rating >= 4\")\n",
    "max(x['unix_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.52 s ± 93.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x = table.read_where(\"rating >= 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  table.iterrows()\n",
    "\n",
    "`table.iterrows()` returns an iterator that iterates over ALL rows, using this iterator, we can avoid loading the table in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 ms ± 42.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = max(x['unix_timestamp'] for x in table.iterrows() if x['rating'] >= 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, but we can do much better still:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### table.where()\n",
    "\n",
    "`table.where()` is an iterator that performs an in-kernel query:\n",
    "\n",
    "It returns a row iterator, that iterates over the selected rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tables.tableextension.Row"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(table.where('rating >= 4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314 ms ± 12.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ts = (row['unix_timestamp'] for row in table.where(\"rating >= 4\"))\n",
    "max(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized vs Denormalized tables\n",
    "\n",
    "Let's compare a \"real life\" query:\n",
    "\n",
    "Query the ratings for the movie `Tom and Huck (1995)`:\n",
    "\n",
    "### Denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5denorm = \"compression/blosc-zstd-5-shuffle-denorm.h5\"\n",
    "h5file = tables.open_file(h5denorm)\n",
    "h5lens = h5file.root.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/lens (Table(1000209,), shuffle, blosc:zstd(5)) ''\n",
       "  description := {\n",
       "  \"user_id\": Int32Col(shape=(), dflt=0, pos=0),\n",
       "  \"rating\": Int8Col(shape=(), dflt=0, pos=1),\n",
       "  \"unix_timestamp\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"title\": StringCol(itemsize=100, shape=(), dflt=b'', pos=3),\n",
       "  \"genres\": StringCol(itemsize=50, shape=(), dflt=b'', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (402,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13 s ± 65.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3c399c9d2cd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mratings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying denormalized tables is easy as pie.  Let's see how to manage normalized ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5norm = \"compression/blosc-zstd-5-shuffle.h5\"\n",
    "h5file = tables.open_file(h5norm)\n",
    "h5ratings = h5file.root.ratings\n",
    "h5movies = h5file.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/ratings (Table(1000209,), shuffle, blosc:zstd(5)) ''\n",
       "  description := {\n",
       "  \"user_id\": Int32Col(shape=(), dflt=0, pos=0),\n",
       "  \"movie_id\": Int32Col(shape=(), dflt=0, pos=1),\n",
       "  \"rating\": Int8Col(shape=(), dflt=0, pos=2),\n",
       "  \"unix_timestamp\": Int64Col(shape=(), dflt=0, pos=3)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (7710,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/movies (Table(3883,), shuffle, blosc:zstd(5)) ''\n",
       "  description := {\n",
       "  \"movie_id\": Int32Col(shape=(), dflt=0, pos=0),\n",
       "  \"title\": StringCol(itemsize=100, shape=(), dflt=b'', pos=1),\n",
       "  \"genres\": StringCol(itemsize=50, shape=(), dflt=b'', pos=2)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (425,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 416 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the query in the normalized version is more than 2~3x faster than using the denormalized file.  However, this is just a simple example, and in general experimentation should be done so as to determine the best layout for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing is a general technique for adding data structures that can accelerate queries.  Let's see how PyTables makes use of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalized case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queries\\\\movielens-denorm-indexed.h5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx = os.path.join(data_dir, \"movielens-denorm-indexed.h5\")\n",
    "if os.path.exists(h5idx):\n",
    "    os.unlink(h5idx)\n",
    "shutil.copyfile(h5denorm, h5idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx, mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the 'title' column\n",
    "h5lens = h5i.root.lens\n",
    "blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "%time h5lens.cols.title.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this time is 100x less than without using indexing.  What if we index the `rating` column too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 778 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the rating column\n",
    "%time h5lens.cols.rating.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(0,6):\n",
    "    ratings[rt] = sum(1 for r in h5lens.where(\"(title == b'Tom and Huck (1995)') & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so although small, this represents another improvement in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queries\\\\movielens-norm-indexed.h5'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx = os.path.join(data_dir, \"movielens-norm-indexed.h5\")\n",
    "if os.path.exists(h5idx):\n",
    "    os.unlink(h5idx)\n",
    "shutil.copyfile(h5norm, h5idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx, mode=\"a\")\n",
    "h5ratings = h5i.root.ratings\n",
    "h5movies = h5i.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 538 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the rating column\n",
    "blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "%time h5ratings.cols.rating.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 426 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, in this case indexing the rating column has not served to accelerate the query (at first sight at least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 618 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the movie_id column\n",
    "%time h5ratings.cols.movie_id.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we see a better acceleration in the query, but cannot compete with the query speed for the denormalized case (which is ~10x faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20M\n",
      "-rw-r--r-- 1 tomkooij 197613 9.9M Jun 20 09:10 movielens-denorm-indexed.h5\n",
      "-rw-r--r-- 1 tomkooij 197613 9.6M Jun 20 09:10 movielens-norm-indexed.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not created an index for the title for the normalized case.  Create such an index and determine if there is a noticeable speed-up or not.  Explain why you think that is the case.  Note: the times for a cold query can be **significatively** different from a hot query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movielens-norm-indexed2.h5'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy the original PyTables table into another file\n",
    "import shutil\n",
    "h5idx2 = \"movielens-norm-indexed2.h5\"\n",
    "if os.path.exists(h5idx2):\n",
    "    os.unlink(h5idx2)\n",
    "shutil.copyfile(h5idx, h5idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-91197a77d2ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Open the new file in 'a'ppend mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mh5i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5idx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mh5ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mh5movies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "# Open the new file in 'a'ppend mode\n",
    "h5i = tables.open_file(h5idx2, mode=\"a\")\n",
    "h5ratings = h5i.root.ratings\n",
    "h5movies = h5i.root.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Solution starts here\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index for the movie_id column\n",
    "%time h5movies.cols.title.create_csindex(filters=blosc_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 253 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratings = [0] * 6\n",
    "for rt in range(6):\n",
    "    th_movie_id = [r['movie_id'] for r in h5movies.where(\"(title == b'Tom and Huck (1995)')\")][0]\n",
    "    ratings[rt] = sum(1 for r in h5ratings.where(\"(movie_id == th_movie_id) & (rating == rt)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 15, 28, 18, 3]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So the first time that the query is done after the cache is built (cold query), the time has been reduced a bit but not too much.  For subsequent queries (hot queries), the times are better, but not reaching the denormalized table either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Query size vs speed (indexed queries vs non-indexed queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "iteration:  1\n",
      "iteration:  2\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "iteration:  6\n",
      "iteration:  7\n",
      "iteration:  8\n",
      "iteration:  9\n",
      "iteration:  10\n",
      "iteration:  11\n",
      "iteration:  12\n",
      "iteration:  13\n",
      "iteration:  14\n",
      "iteration:  15\n",
      "iteration:  16\n",
      "iteration:  17\n",
      "iteration:  18\n",
      "iteration:  19\n",
      "iteration:  20\n",
      "iteration:  21\n",
      "iteration:  22\n",
      "iteration:  23\n",
      "iteration:  24\n",
      "iteration:  25\n",
      "iteration:  26\n",
      "iteration:  27\n",
      "iteration:  28\n",
      "iteration:  29\n",
      "iteration:  30\n",
      "iteration:  31\n",
      "iteration:  32\n",
      "iteration:  33\n",
      "iteration:  34\n",
      "iteration:  35\n",
      "iteration:  36\n",
      "iteration:  37\n",
      "iteration:  38\n",
      "iteration:  39\n",
      "iteration:  40\n",
      "iteration:  41\n",
      "iteration:  42\n",
      "iteration:  43\n",
      "iteration:  44\n",
      "iteration:  45\n",
      "iteration:  46\n",
      "iteration:  47\n",
      "iteration:  48\n",
      "iteration:  49\n",
      "iteration:  50\n",
      "iteration:  51\n",
      "iteration:  52\n",
      "iteration:  53\n",
      "iteration:  54\n",
      "iteration:  55\n",
      "iteration:  56\n",
      "iteration:  57\n",
      "iteration:  58\n",
      "iteration:  59\n",
      "iteration:  60\n",
      "iteration:  61\n",
      "iteration:  62\n",
      "iteration:  63\n",
      "iteration:  64\n",
      "iteration:  65\n",
      "iteration:  66\n",
      "iteration:  67\n",
      "iteration:  68\n",
      "iteration:  69\n",
      "iteration:  70\n",
      "iteration:  71\n",
      "iteration:  72\n",
      "iteration:  73\n",
      "iteration:  74\n",
      "iteration:  75\n",
      "iteration:  76\n",
      "iteration:  77\n",
      "iteration:  78\n",
      "iteration:  79\n",
      "iteration:  80\n",
      "iteration:  81\n",
      "iteration:  82\n",
      "iteration:  83\n",
      "iteration:  84\n",
      "iteration:  85\n",
      "iteration:  86\n",
      "iteration:  87\n",
      "iteration:  88\n",
      "iteration:  89\n",
      "iteration:  90\n",
      "iteration:  91\n",
      "iteration:  92\n",
      "iteration:  93\n",
      "iteration:  94\n",
      "iteration:  95\n",
      "iteration:  96\n",
      "iteration:  97\n",
      "iteration:  98\n",
      "iteration:  99\n",
      "iteration:  100\n",
      "iteration:  101\n",
      "iteration:  102\n",
      "iteration:  103\n",
      "iteration:  104\n",
      "iteration:  105\n",
      "iteration:  106\n",
      "iteration:  107\n",
      "iteration:  108\n",
      "iteration:  109\n",
      "iteration:  110\n",
      "iteration:  111\n",
      "iteration:  112\n",
      "iteration:  113\n",
      "iteration:  114\n",
      "iteration:  115\n",
      "iteration:  116\n",
      "iteration:  117\n",
      "iteration:  118\n",
      "iteration:  119\n",
      "iteration:  120\n",
      "iteration:  121\n",
      "iteration:  122\n",
      "iteration:  123\n",
      "iteration:  124\n",
      "iteration:  125\n",
      "iteration:  126\n",
      "iteration:  127\n",
      "iteration:  128\n",
      "iteration:  129\n",
      "iteration:  130\n",
      "iteration:  131\n",
      "iteration:  132\n",
      "iteration:  133\n",
      "iteration:  134\n",
      "iteration:  135\n",
      "iteration:  136\n",
      "iteration:  137\n",
      "iteration:  138\n",
      "iteration:  139\n",
      "iteration:  140\n",
      "iteration:  141\n",
      "iteration:  142\n",
      "iteration:  143\n",
      "iteration:  144\n",
      "iteration:  145\n",
      "iteration:  146\n",
      "iteration:  147\n",
      "iteration:  148\n",
      "iteration:  149\n",
      "iteration:  150\n",
      "iteration:  151\n",
      "iteration:  152\n",
      "iteration:  153\n",
      "iteration:  154\n",
      "iteration:  155\n",
      "iteration:  156\n",
      "iteration:  157\n",
      "iteration:  158\n",
      "iteration:  159\n",
      "iteration:  160\n",
      "iteration:  161\n",
      "iteration:  162\n",
      "iteration:  163\n",
      "iteration:  164\n",
      "iteration:  165\n",
      "iteration:  166\n",
      "iteration:  167\n",
      "iteration:  168\n",
      "iteration:  169\n",
      "iteration:  170\n",
      "iteration:  171\n",
      "iteration:  172\n",
      "iteration:  173\n",
      "iteration:  174\n",
      "iteration:  175\n",
      "iteration:  176\n",
      "iteration:  177\n",
      "iteration:  178\n",
      "iteration:  179\n",
      "iteration:  180\n",
      "iteration:  181\n",
      "iteration:  182\n",
      "iteration:  183\n",
      "iteration:  184\n",
      "iteration:  185\n",
      "iteration:  186\n",
      "iteration:  187\n",
      "iteration:  188\n",
      "iteration:  189\n",
      "iteration:  190\n",
      "iteration:  191\n",
      "iteration:  192\n",
      "iteration:  193\n",
      "iteration:  194\n",
      "iteration:  195\n",
      "iteration:  196\n",
      "iteration:  197\n",
      "iteration:  198\n",
      "iteration:  199\n"
     ]
    }
   ],
   "source": [
    "# adapted from: https://stackoverflow.com/questions/20769818/\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "class KeyValue(tables.IsDescription):\n",
    "    key = tables.StringCol(itemsize=30, dflt=\" \", pos=0)  \n",
    "    value = tables.Int64Col(dflt=0, pos=1)\n",
    "\n",
    "fn = os.path.join(data_dir, \"keyvalue.h5\")\n",
    "\n",
    "with tables.open_file(fn, \"w\") as f:    \n",
    "    filters = tables.Filters(complevel=5, complib='blosc')\n",
    "    kv = f.create_table(\"/\", \"keyvalues\", KeyValue, filters=filters)\n",
    "\n",
    "    for j in range(200):\n",
    "        values = []\n",
    "        print('iteration: ', j)\n",
    "        for _ in range(100000):\n",
    "            key = \"\".join(random.sample(string.ascii_uppercase, 10))  # slow!\n",
    "            value = random.randint(0, 1000000)\n",
    "            values.append((key, value))\n",
    "        kv.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/keyvalues (Table(20000000,), shuffle, blosc(5)) ''\n",
      "  description := {\n",
      "  \"key\": StringCol(itemsize=30, shape=(), dflt=b' ', pos=0),\n",
      "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (1724,)\n",
      "  Data dump:\n",
      "[0] (b'QPGONRWHJX', 651797)\n",
      "[1] (b'HNGTUJYKAP', 313014)\n",
      "[2] (b'NRALQITYZV', 225736)\n",
      "[3] (b'YPLNGDVTHK', 210883)\n",
      "[4] (b'BXGIQLMFUE', 482386)\n",
      "[5] (b'OUSZQHPGFJ', 52527)\n",
      "[6] (b'GTZVRCMYNJ', 107035)\n",
      "[7] (b'CVAIYMLQHU', 92337)\n",
      "[8] (b'RYZCGWBTXL', 143533)\n",
      "[9] (b'HGOUALQSIC', 888223)\n"
     ]
    }
   ],
   "source": [
    "!ptdump -v -R10 {fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value=10 : len=18\n",
      "max_value=50 : len=52\n",
      "max_value=100 : len=99\n",
      "max_value=1000 : len=971\n",
      "max_value=10000 : len=10031\n",
      "\n",
      "without index:\n",
      "Wall time: 76.1 ms\n",
      "Wall time: 82.6 ms\n",
      "Wall time: 72.6 ms\n",
      "Wall time: 85 ms\n",
      "Wall time: 74.5 ms\n",
      "\n",
      "indexing...\n",
      "Wall time: 1.66 s\n",
      "\n",
      "with index\n",
      "Wall time: 8.01 ms\n",
      "Wall time: 8.52 ms\n",
      "Wall time: 18 ms\n",
      "Wall time: 73.6 ms\n",
      "Wall time: 92.6 ms\n"
     ]
    }
   ],
   "source": [
    "max_values = [10, 50, 100, 1000, 10000]\n",
    "\n",
    "with tables.open_file(fn, \"a\") as f:\n",
    "    kv = f.root.keyvalues\n",
    "\n",
    "    kv.cols.value.remove_index()\n",
    "\n",
    "    for max_value in max_values:\n",
    "        print('max_value=%d : len=%d' % (max_value, len(kv.read_where('value < %s' % max_value))))\n",
    "    \n",
    "    print('\\nwithout index:')\n",
    "    for max_value in max_values:\n",
    "        #%time kv.read_where('value < %s' % max_value)\n",
    "        %time sum(1 for x in kv.where('value < %s' % max_value))\n",
    "\n",
    "    blosc_filter = tables.Filters(complevel=9, complib=\"blosc\")\n",
    "    print('\\nindexing...')\n",
    "    %time kv.cols.value.create_csindex()\n",
    "\n",
    "    print('\\nwith index')\n",
    "    for max_value in max_values:\n",
    "        #%time kv.read_where('value < %s' % max_value)\n",
    "        %time sum(1 for x in kv.where('value < %s' % max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = tables.open_file(fn, 'r')\n",
    "f\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=queries\\keyvalue.h5, title='', mode='r', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/keyvalues (Table(10000000,)) ''\n",
       "  description := {\n",
       "  \"key\": StringCol(itemsize=30, shape=(), dflt=b' ', pos=0),\n",
       "  \"value\": Int64Col(shape=(), dflt=0, pos=1)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (1724,)\n",
       "  autoindex := True\n",
       "  colindexes := {\n",
       "    \"value\": Index(9, full, shuffle, zlib(1)).is_csi=True}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
